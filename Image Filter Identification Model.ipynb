{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a09084",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ce4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "^C\n",
      "Requirement already satisfied: opendatasets in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (4.66.1)\n",
      "Requirement already satisfied: kaggle in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (1.6.17)\n",
      "Requirement already satisfied: click in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2.31.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (6.0.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->opendatasets) (2.10)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: pillow in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\moksh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.22.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow\n",
    "!pip install opendatasets\n",
    "!pip install opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d30d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import opendatasets as ds\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kaggle.com/datasets/lprdosmil/unsplash-random-images-collection\"\n",
    "data = ds.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c61760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'Filter Identification/unsplash-random-images-collection/unsplash-random-images-collection'  \n",
    "output_folder = 'filtered_images_output'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331634e",
   "metadata": {},
   "source": [
    "## Sepia Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b37d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sepia(image):\n",
    "    sepia_filter = np.array([[0.272, 0.534, 0.131],\n",
    "                             [0.349, 0.686, 0.168],\n",
    "                             [0.393, 0.769, 0.189]])\n",
    "    sepia_img = cv2.transform(image, sepia_filter)\n",
    "    return np.clip(sepia_img, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a6d25",
   "metadata": {},
   "source": [
    "## Black and White (B&W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_black_and_white(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0f9d5",
   "metadata": {},
   "source": [
    "## Vintage Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93767610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vintage(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    vignette_filter = np.zeros((rows, cols), np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            vignette_filter[i, j] = 255 * (1 - ((i / rows) ** 2 + (j / cols) ** 2) ** 0.5)\n",
    "    vintage_img = cv2.applyColorMap(image, cv2.COLORMAP_PINK)\n",
    "    return cv2.addWeighted(image, 0.7, vintage_img, 0.3, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66b65b",
   "metadata": {},
   "source": [
    "## Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bcd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(image):\n",
    "    return cv2.GaussianBlur(image, (15, 15), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c654c",
   "metadata": {},
   "source": [
    "## Saturation Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab25e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_saturation_boost(image):\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_img[:, :, 1] = cv2.add(hsv_img[:, :, 1], 50)\n",
    "    return cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422229ba",
   "metadata": {},
   "source": [
    "## Vivid Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vivid(image):\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_img[:, :, 1] = cv2.add(hsv_img[:, :, 1], 75)  # Increase saturation more\n",
    "    return cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99c247",
   "metadata": {},
   "source": [
    "## Warm Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_warm(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    r = cv2.add(r, 30)  # Add warmth to the red channel\n",
    "    return cv2.merge((b, g, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f567a3",
   "metadata": {},
   "source": [
    "## Cool Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27313da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cool(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    b = cv2.add(b, 30)  # Add coolness to the blue channel\n",
    "    return cv2.merge((b, g, r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce57ae9",
   "metadata": {},
   "source": [
    "## Soft Focus Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bea3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_soft_focus(image):\n",
    "    blurred = cv2.GaussianBlur(image, (21, 21), 0)\n",
    "    return cv2.addWeighted(image, 0.5, blurred, 0.5, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c984f51",
   "metadata": {},
   "source": [
    "## Film Grain Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_film_grain(image):\n",
    "    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)  # Add noise\n",
    "    return cv2.add(image, noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae0966",
   "metadata": {},
   "source": [
    "## Cartoon Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cartoon(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    edges = cv2.adaptiveThreshold(gray, 255,\n",
    "                                   cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                   cv2.THRESH_BINARY, 9, 9)\n",
    "    color = cv2.bilateralFilter(image, 9, 300, 300)\n",
    "    return cv2.bitwise_and(color, color, mask=edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0e455",
   "metadata": {},
   "source": [
    "## Dramatic Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53331b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dramatic(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    return cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14e505",
   "metadata": {},
   "source": [
    "## Apply Filters and Save Images in Separate Folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af970a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply filter and save image\n",
    "def apply_and_save_filter(image, filter_func, filter_name, img_name, output_folder):\n",
    "    filter_folder = os.path.join(output_folder, filter_name)\n",
    "    Path(filter_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filtered_img = filter_func(image)\n",
    "    output_path = os.path.join(filter_folder, img_name)\n",
    "    cv2.imwrite(output_path, filtered_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d2198",
   "metadata": {},
   "source": [
    "## Function to process images in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(input_folder, output_folder):\n",
    "    filters = {\n",
    "        \"Sepia\": apply_sepia,\n",
    "        \"Black and White (B&W)\": apply_black_and_white,\n",
    "        \"Vintage\": apply_vintage,\n",
    "        \"Gaussian Blur\": apply_gaussian_blur,\n",
    "        \"Saturation Boost\": apply_saturation_boost,\n",
    "        \"Vivid\": apply_vivid,\n",
    "        \"Warm\": apply_warm,\n",
    "        \"Cool\": apply_cool,\n",
    "        \"Soft Focus\": apply_soft_focus,\n",
    "        \"Film Grain\": apply_film_grain,\n",
    "        \"Cartoon\": apply_cartoon,\n",
    "        \"Dramatic\": apply_dramatic\n",
    "    }\n",
    "\n",
    "    for img_name in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is not None:\n",
    "            for filter_name, filter_func in filters.items():\n",
    "                apply_and_save_filter(image, filter_func, filter_name, img_name, output_folder)\n",
    "        else:\n",
    "            print(f\"Could not read image {img_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6580f",
   "metadata": {},
   "source": [
    "## Define your dataset and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_folder = 'C:/Users/moksh/OneDrive/Desktop/Filter Identification/unsplash-random-images-collection/unsplash-images-collection'  # Replace with your path\n",
    "output_folder = 'C:/Users/moksh/OneDrive/Desktop/Filter Identification/Filtered dataset'  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23100a",
   "metadata": {},
   "source": [
    "## Apply the filters and save the processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c5ea5",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeee585",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1908046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = 'C:/Users/moksh/OneDrive/Desktop/Filter Identification/Filtered dataset'  \n",
    "\n",
    "# Set up parameters\n",
    "image_size = (150, 150)  # Adjust according to your needs\n",
    "batch_size = 32\n",
    "\n",
    "# Create an ImageDataGenerator for loading images\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load the data from the directory\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'sparse_categorical' if labels are integers\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04e63d",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c91c5",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e692fa5",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3060287",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder ='C:/Users/moksh/OneDrive/Desktop/Filter Identification/models'  \n",
    "\n",
    "\n",
    "model_save_path = os.path.join(project_folder, 'filter_classification_model.h5')\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"Model saved at: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1ec90",
   "metadata": {},
   "source": [
    "# Testing With Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('filter_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9048546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(150, 150)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Make the prediction\n",
    "    predictions = model.predict(image)\n",
    "    \n",
    "    # Get the class index with the highest probability\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    \n",
    "    # Get the class labels\n",
    "    class_labels = list(train_generator.class_indices.keys())\n",
    "    \n",
    "    # Return the predicted label\n",
    "    return class_labels[predicted_class_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f773e",
   "metadata": {},
   "source": [
    "## Testing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9536ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'C:/Users/moksh/OneDrive/Desktop/Filter Identification/Testing images/images.jpg'\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = predict_image(test_image_path)\n",
    "print(f'The predicted label for the image is: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc623314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'C:/Users/moksh/OneDrive/Desktop/Filter Identification/Filtered dataset'  # Replace with your actual path\n",
    "\n",
    "# Parameters\n",
    "image_size = (150, 150)  # Adjust as per your model's input size\n",
    "batch_size = 32\n",
    "\n",
    "# Data Generator with validation split (80% train, 20% test)\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
    "\n",
    "# Training Data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # This is the training set\n",
    ")\n",
    "\n",
    "# Validation/Test Data\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # This is the test set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get a random batch from the test set\n",
    "x_test, y_test = next(test_generator)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Convert predictions and true labels to readable format\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Get class labels\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Display results for a random image from the batch\n",
    "import random\n",
    "i = random.randint(0, batch_size - 1)\n",
    "print(f\"Predicted Label: {class_labels[predicted_labels[i]]}\")\n",
    "print(f\"True Label: {class_labels[true_labels[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbce926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
